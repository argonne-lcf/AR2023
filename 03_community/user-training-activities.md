---
layout: page

title: Training ALCF Users
hero-img-source: "GPUHackathon-group.png"
hero-img-caption: "The 2022 ALCF-NVIDIA GPU Hackathon hosted 15 teams to help them get their applications running efficiently on the facility's GPU-accelerated systems."

theme: white
permalink: community-and-outreach/user-training-activities
---


# ALCF AI Testbed Training Workshops  
Starting July of 2023, the ALCF hosted a series of training workshops that introduced users to the novel AI accelerators deployed at the ALCF AI Testbed. The four individual workshops introduced participants to the architecture and software of the SambaNova DataScale SN30, the Cerebras CS-2 system, the Graphcore Bow Pod system, and the GroqRack System. All series were open to the public and videos of all talks are posted to the [ALCF website](https://www.alcf.anl.gov/events) and [YouTube channel](https://www.youtube.com/@argonneleadershipcomputing8396). 

# ALCF Computational Performance Workshop
Held in October, the annual ALCF Computational Performance Workshop is designed to help attendees boost application performance on ALCF systems. With dedicated access to ALCF computing resources, the three-day workshop allowed workshop participants to work directly with ALCF and invited experts to test, debug, and optimize their applications. One of the workshop’s primary goals is to help researchers demonstrate code scalability for INCITE, ALCC, and ADSP project proposals, which are required to convey both scientific merit and computational readiness.

# ALCF INCITE Hackathon
In April and May, the ALCF partnered with NVIDIA to host its GPU Hackathon for the third time, a hybrid event designed to help developers accelerate their codes on ALCF resources using a portable programming model, such as OpenMP, or an AI framework of their choice. The multi-day hackathon gave attendees access to ALCF’s Polaris system, an HPE Apollo Gen10+ machine equipped with NVIDIA A100 Tensor Core GPUs and AMD EPYC processors. A total of 12 teams participated this year, researching a vast array of topics including weather research and forecasting models, colon cancer research and methods to reconstruct large biomolecular structures.

{% include media-img.html
   source= "ATPESC-classroom.jpg"
   caption= "The Argonne Training Program on Extreme-Scale Computing (ATPESC) teaches attendees the key tools and techniques to use supercomputers for scientific research."
%}

# ATPESC 2023
The annual Argonne Training Program on Extreme-Scale Computing (ATPESC), marked its 11th year in 2023. The two-week training event offers training on key skills, approaches, and tools needed to design, implement, and execute computational science and engineering applications on high-end computing systems, including upcoming exascale supercomputers. Organized by ALCF staff and funded by the ECP, ATPESC has a core curriculum that covers computer architectures; programming methodologies; data-intensive computing and I/O; numerical algorithms and mathematical software; performance and debugging tools; software productivity; data analysis and visualization; and machine learning and data science. More than 70 graduate students, postdocs, and career professionals in computational science and engineering attended this year’s program. ATPESC has now hosted more than 600 participants since it began in 2013.  

# Aurora Learning Paths
The ALCF in collaboration with Intel Software continued hosting their Aurora Learning Paths series with a total of 3 separate series running in 2023. The three series covered migrating from CUDA to SYCL, accelerating Python Loops with the Intel AI Analytics Toolkit, and GPU optimization using SYCL. All webinar series were open to the public and videos of all talks are posted to the [ALCF website](https://www.alcf.anl.gov/events) and [YouTube channel](https://www.youtube.com/@argonneleadershipcomputing8396). 

# Aurora Workshop
This invitation-only workshop focused on helping ESP and ECP researchers prepare applications and software technologies for Aurora. The workshop was geared toward developers and emphasized using the Intel software development kit to get applications running on testbed hardware. Teams were also given the opportunity to consult with ALCF staff and provide feedback. The workshop kicked off in June with the initial sessions focused on presentations and status updates on Aurora’s hardware and software. ALCF staff also held dedicated office hours on a range of topics from programming models to profiling tools.

# Best Practices for HPC Software Developers
In 2023, the ALCF, OLCF, NERSC, and ECP continued their collaboration with the Interoperable Design of Extreme-Scale Application Software (IDEAS) project to deliver a series of webinars—Best Practices for HPC Software Developers—to help users of HPC systems carry out their software development more productively. Webinar topics included the lab notebooks for computational mathematics, Openscapes for environmental science to help uncover data-driven solutions faster, managing academic software development, and how the ability to “import” a package is critical in enabling technology for software re-use.

{% include media-img.html
   source= "ALCF-SDLWksp1.png"
   caption= "Training events like the annual Simulation, Data, and Learning Workshop are helping to build a community of researchers who can employ ALCF supercomputing resources to advance AI- and data-driven research."
%}

# Getting Started Bootcamp on Polaris
The ALCF Getting Started Bootcamp introduced attendees to using the Polaris computing environment. Aimed at participants who have experience using clusters or supercomputers, the bootcamp covered the PBS job scheduler, utilizing preinstalled environments, proper compiler and profiler use, Python environments, and running Jupyter notebooks. The webinar showed those in attendance where these tools are located and which ones to use.

# Monthly ALCF Webinars
The ALCF continued to host monthly webinars consisting of two tracks: ALCF Developer Sessions and Aurora Early Adopters Series. ALCF Developer Sessions are aimed at training researchers and increasing the dialogue between HPC users and the developers of leadership-class systems and software. Speakers in the series included developers from NVIDIA and Argonne, covering topics such as getting started on Aurora, computing with ALCF JupyterHub, and preparing XGC and HACC to run on Aurora. The Aurora Early Adopter Series is designed to introduce researchers to programming models, exascale technologies, and other tools available for testing and development work. Topics included optimizing SYCL workloads for Aurora, CUDA to SYCL migration tool, and how to apply key Intel architectural innovations via smart application of NumPy, SciPy, and Pandas techniques to achieve performance gains. 

