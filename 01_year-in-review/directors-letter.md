---
layout: page

theme: white
permalink: year-in-review/directors-letter

title: Director&rsquo;s Letter
hero-img-source: "papka.png"
hero-img-caption: "Michael E. Papka, ALCF Director"
---

The process of planning for and installing a supercomputer takes years. It includes a critical period of stabilizing the system through validation, verification, and scale-up activities, which can vary for each machine. However, unlike ALCF’s previous or current production machines, Aurora’s long ramp-up journey has also included several configuration changes and Covid-related supply chain issues. 

Aurora will be used for many AI and scientific computing applications and to train a 1-trillion-parameter large language model for scientific research. Its architecture features more endpoints in the interconnect technology than any other system, and its more than 60,000 GPUs make it the largest GPU installation in the world.

In 2023, ALCF made significant progress toward realizing Aurora’s full capabilities. In June, Aurora completed the installation of its 10,624th and final blade. Shortly after, Argonne shared the results of high-performance Linpack runs for a part of Aurora to the TOP500. These results were used in the November announcement of the world’s fastest supercomputers, where Aurora secured the second position. Once the full system goes online, it will surpass two exaflops.

Some application teams participating in the DOE’s Exascale Computing Project and the ALCF’s Aurora Early Science Program have begun using Aurora to scale and optimize their applications for the system’s initial science campaigns. Soon to follow will be all the early science teams and an additional 24 INCITE research teams in 2024.

This new exascale machine brings with it some more big changes. Theta, one of ALCF’s production systems, was retired on December 31, 2023. ThetaGPU will be decoupled and reconfigured to become a new system named Sophia and will be used to train large language models. Polaris will replace Cooley, now retired, and serve as ALCF’s primary production resource for visualization and analysis. Meanwhile, the ALCF AI Testbed will continue to make more production systems available to the research community.

For more than a decade, researchers at Argonne have been developing tools and methods that connect powerful computing resources with large-scale experiments, such as the Advanced Photon Source and the DIII-D National Fusion Facility. Their work is shaping the future of inter-facility workflows by automating them and identifying ways to make these workflows reusable and adaptable for different experiments. Argonne’s Nexus initiative, in which ALCF plays a key role, offers the framework for a unified platform to manage high-throughput workflows across the HPC landscape.

I’m highlighting this activity here, and you will read more about it in the pages that follow because Nexus is advancing the Department of Energy’s big vision to build a broadscale Integrated Research Infrastructure (IRI) to enable experimental facilities to leverage supercomputing facilities for experiment-time data analysis. The IRI will enable real-time data analysis and accelerate the next generation of data-intensive research by combining scientific facilities, supercomputing capabilities, and new data technologies like AI, machine learning, and edge computing.

In 2023, we continued our commitment to education and workforce development by organizing a number of informative learning experiences and training events. As part of this effort, ALCF staff members led a pilot program called “Introduction to High-Performance Computing Bootcamp” at Lawrence Berkeley National Laboratory. This was an immersive program designed for students in STEM to work on energy justice projects using computational and data science tools learned throughout the week. In a separate effort, the ALCF worked on developing the curriculum for its “Intro to AI-Driven Science on Supercomputers” training course, with the aim of adapting the content to introduce undergraduates and graduates to the basics of large language models for future course offerings.

To conclude, I would like to express my sincere gratitude to the exceptional staff, vendor partners, and program office, who have all contributed to making ALCF one of the leading scientific supercomputing facilities in the world. While there are many more exciting changes on the horizon, I truly appreciate taking the time each year to share our numerous achievements with you in our Annual Report.


